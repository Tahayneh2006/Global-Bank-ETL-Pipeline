{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline: Top 10 Largest Banks\n",
    "**Project Description:**\n",
    "This notebook implements an automated ETL (Extract, Transform, Load) pipeline to compile a list of the top 10 largest banks in the world by market capitalization. The data is scraped from Wikipedia, transformed using current exchange rates for GBP, EUR, and INR, and loaded into both a CSV file and a SQLite database.\n",
    "\n",
    "**Author:** Malik Tahayneh\n",
    "\n",
    "**Date:** December 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries (Run this once if needed)\n",
    "!pip install requests bs4 pandas numpy lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cd53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "remote_url = 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv'\n",
    "local_csv_name = 'exchange_rate.csv'\n",
    "\n",
    "try:\n",
    "    response = requests.get(remote_url)\n",
    "    if response.status_code == 200:\n",
    "        with open(local_csv_name, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Success: {local_csv_name} downloaded.\")\n",
    "    else:\n",
    "        print(\"Error: Failed to download CSV.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "url = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "exchange_rate_path = f'./{local_csv_name}'  # Point to the downloaded file\n",
    "table_attribs_extraction = ['Name', 'MC_USD_Billion']\n",
    "output_csv_path = './Largest_banks_data.csv'\n",
    "db_name = 'Banks.db'\n",
    "table_name = 'Largest_banks'\n",
    "log_file = 'code_log.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e6bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message):\n",
    "    ''' Logs the execution stage to a file with a timestamp. '''\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' \n",
    "    now = datetime.now() \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    \n",
    "    with open(log_file,\"a\") as f: \n",
    "        f.write(timestamp + ' : ' + message + '\\n')\n",
    "        \n",
    "    print(f\"Logged: {message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313da633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(url, table_attribs):\n",
    "    ''' Scrapes the website and returns a dataframe with Bank Name and Market Cap (USD). '''\n",
    "    \n",
    "    page = requests.get(url).text\n",
    "    data = BeautifulSoup(page, 'html.parser')\n",
    "    \n",
    "    df_list = []\n",
    "    \n",
    "    # Locate the first table under 'By market capitalization'\n",
    "    tables = data.find_all('tbody')\n",
    "    rows = tables[0].find_all('tr') \n",
    "    \n",
    "    for row in rows:\n",
    "        col = row.find_all('td')\n",
    "        if len(col) != 0:\n",
    "            if col[1].find('a') is not None:\n",
    "                name = col[1].find('a').contents[0]\n",
    "                market_cap = col[2].contents[0]\n",
    "                market_cap = float(market_cap.strip())\n",
    "                \n",
    "                df_list.append({table_attribs[0]: name, table_attribs[1]: market_cap})\n",
    "\n",
    "    df = pd.DataFrame(df_list, columns=table_attribs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eedadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, csv_path):\n",
    "    ''' Adds columns for GBP, EUR, and INR based on exchange rates. '''\n",
    "    \n",
    "    # Read exchange rate CSV\n",
    "    exchange_rate = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Convert to dictionary: {'Currency': Rate}\n",
    "    exchange_rate_dict = exchange_rate.set_index('Currency').to_dict()['Rate']\n",
    "    \n",
    "    # Add new columns\n",
    "    df['MC_GBP_Billion'] = [np.round(x * exchange_rate_dict['GBP'], 2) for x in df['MC_USD_Billion']]\n",
    "    df['MC_EUR_Billion'] = [np.round(x * exchange_rate_dict['EUR'], 2) for x in df['MC_USD_Billion']]\n",
    "    df['MC_INR_Billion'] = [np.round(x * exchange_rate_dict['INR'], 2) for x in df['MC_USD_Billion']]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ecb980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_csv(df, output_path):\n",
    "    ''' Saves the dataframe to a CSV file. '''\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "def load_to_db(df, sql_connection, table_name):\n",
    "    ''' Saves the dataframe to a SQL database table. '''\n",
    "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n",
    "\n",
    "def run_query(query_statement, sql_connection):\n",
    "    ''' Runs a SQL query and prints the output. '''\n",
    "    print(f\"\\nQuery: {query_statement}\")\n",
    "    query_output = pd.read_sql(query_statement, sql_connection)\n",
    "    print(query_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aa65ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execution Block ---\n",
    "\n",
    "# 1. Start Process\n",
    "log_progress('Preliminaries complete. Initiating ETL process')\n",
    "\n",
    "# 2. Extract\n",
    "df = extract(url, table_attribs_extraction)\n",
    "log_progress('Data extraction complete. Initiating Transformation process')\n",
    "print(\"\\nExtracted Data (First 5 rows):\")\n",
    "display(df.head()) \n",
    "\n",
    "# 3. Transform\n",
    "df = transform(df, exchange_rate_path)\n",
    "log_progress('Data transformation complete. Initiating Loading process')\n",
    "print(\"\\nTransformed Data (First 5 rows):\")\n",
    "display(df.head())\n",
    "\n",
    "# 4. Load to CSV\n",
    "load_to_csv(df, output_csv_path)\n",
    "log_progress('Data saved to CSV file')\n",
    "\n",
    "# 5. Load to Database\n",
    "sql_connection = sqlite3.connect(db_name)\n",
    "log_progress('SQL Connection initiated.')\n",
    "\n",
    "load_to_db(df, sql_connection, table_name)\n",
    "log_progress('Data loaded to Database as table. Running the query')\n",
    "\n",
    "# 6. Run Queries\n",
    "query_1 = f\"SELECT * from {table_name}\"\n",
    "run_query(query_1, sql_connection)\n",
    "\n",
    "query_2 = f\"SELECT AVG(MC_GBP_Billion) FROM {table_name}\"\n",
    "run_query(query_2, sql_connection)\n",
    "\n",
    "query_3 = f\"SELECT Name from {table_name} LIMIT 5\"\n",
    "run_query(query_3, sql_connection)\n",
    "\n",
    "log_progress('Process Complete.')\n",
    "\n",
    "# 7. Close Connection\n",
    "sql_connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
